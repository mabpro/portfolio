{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56a19b8",
   "metadata": {},
   "source": [
    "<h1>Ozempic Side Effects NLP<h1/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af9f87",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<h2>Libraries<h2/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3be3ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e7fce",
   "metadata": {},
   "source": [
    "<h2>hello<h2/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3d0f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment\n",
      "0  If you’ve been off of any GLP-1 type peptide f...\n",
      "1  Is he the jerk it sounds like he is?  He must ...\n",
      "2  Honestly that’s heartbreaking her mom does tha...\n",
      "3  No. As dogs do not prepare their own food, it'...\n",
      "4  No.\\n\\nDo you need help building a diet plan f...\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "# PRAW Setup\n",
    "reddit = praw.Reddit(\n",
    "    client_id='FsHBk7J5OcNXIh2OmzXWOg',\n",
    "    client_secret='oFwrVTKJgbRcjslvDCp0iM6d9RO7Xw',\n",
    "    user_agent='MB WebScrapping by u/ActualConfusion3366'\n",
    ")\n",
    "\n",
    "count = 0\n",
    "comments = []\n",
    "for post in reddit.subreddit('all').search(\"ozempic\", sort=\"new\", limit=None):\n",
    "    post.comments.replace_more(limit=0)\n",
    "    \"\"\"print(f\"Title: {post.title}\")\n",
    "    print(f\"Score: {post.score}\")\n",
    "    print(f\"URL: {post.url}\")\n",
    "    print(\"-\" * 50)\"\"\"\n",
    "    count += 1\n",
    "    for comment in post.comments[:5]:\n",
    "        comments.append(comment.body)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(comments, columns=[\"comment\"])   \n",
    "print(df.head())\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba53e7",
   "metadata": {},
   "source": [
    "<h2>hello<h2/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "babb3967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mab23\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you’ve been off of any GLP-1 type peptide f...</td>\n",
       "      <td>you’ve glp1 type peptide 3 months act like you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is he the jerk it sounds like he is?  He must ...</td>\n",
       "      <td>jerk sounds like must feel like loser failure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honestly that’s heartbreaking her mom does tha...</td>\n",
       "      <td>honestly that’s heartbreaking mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No. As dogs do not prepare their own food, it'...</td>\n",
       "      <td>dogs prepare food easy put weight loss diet se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No.\\n\\nDo you need help building a diet plan f...</td>\n",
       "      <td>need help building diet plan dog hypothetical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>I need this shirt I hope they release it again!</td>\n",
       "      <td>need shirt hope release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Any notable departures in their patent departm...</td>\n",
       "      <td>notable departures patent department last year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Fortune falsely cites \"a recent report in *Sci...</td>\n",
       "      <td>fortune falsely cites recent report science ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>![gif](giphy|GDnomdqpSHlIs)</td>\n",
       "      <td>gifgiphygdnomdqpshlis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>They claim there was no mistake and this was “...</td>\n",
       "      <td>claim mistake “carefully considered” but…why</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  \\\n",
       "0    If you’ve been off of any GLP-1 type peptide f...   \n",
       "1    Is he the jerk it sounds like he is?  He must ...   \n",
       "2    Honestly that’s heartbreaking her mom does tha...   \n",
       "3    No. As dogs do not prepare their own food, it'...   \n",
       "4    No.\\n\\nDo you need help building a diet plan f...   \n",
       "..                                                 ...   \n",
       "668    I need this shirt I hope they release it again!   \n",
       "669  Any notable departures in their patent departm...   \n",
       "671  Fortune falsely cites \"a recent report in *Sci...   \n",
       "672                        ![gif](giphy|GDnomdqpSHlIs)   \n",
       "673  They claim there was no mistake and this was “...   \n",
       "\n",
       "                                          cleaned_post  \n",
       "0    you’ve glp1 type peptide 3 months act like you...  \n",
       "1    jerk sounds like must feel like loser failure ...  \n",
       "2                    honestly that’s heartbreaking mom  \n",
       "3    dogs prepare food easy put weight loss diet se...  \n",
       "4        need help building diet plan dog hypothetical  \n",
       "..                                                 ...  \n",
       "668                            need shirt hope release  \n",
       "669  notable departures patent department last year...  \n",
       "671  fortune falsely cites recent report science ac...  \n",
       "672                              gifgiphygdnomdqpshlis  \n",
       "673       claim mistake “carefully considered” but…why  \n",
       "\n",
       "[668 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Step 1: Text Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df = df[~df['comment'].isin([\"[deleted]\", \"[removed]\"])]\n",
    "df['cleaned_post'] = df['comment'].apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7bb350",
   "metadata": {},
   "source": [
    "<h2>hello<h2/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77d60bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 15511 stored elements and shape (668, 4896)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['cleaned_post'])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2fa57e",
   "metadata": {},
   "source": [
    "<h2>hello<h2/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cea03f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_post</th>\n",
       "      <th>cluster</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you’ve been off of any GLP-1 type peptide f...</td>\n",
       "      <td>you’ve glp1 type peptide 3 months act like you...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is he the jerk it sounds like he is?  He must ...</td>\n",
       "      <td>jerk sounds like must feel like loser failure ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honestly that’s heartbreaking her mom does tha...</td>\n",
       "      <td>honestly that’s heartbreaking mom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No. As dogs do not prepare their own food, it'...</td>\n",
       "      <td>dogs prepare food easy put weight loss diet se...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No.\\n\\nDo you need help building a diet plan f...</td>\n",
       "      <td>need help building diet plan dog hypothetical</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>I need this shirt I hope they release it again!</td>\n",
       "      <td>need shirt hope release</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Any notable departures in their patent departm...</td>\n",
       "      <td>notable departures patent department last year...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Fortune falsely cites \"a recent report in *Sci...</td>\n",
       "      <td>fortune falsely cites recent report science ac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>![gif](giphy|GDnomdqpSHlIs)</td>\n",
       "      <td>gifgiphygdnomdqpshlis</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>They claim there was no mistake and this was “...</td>\n",
       "      <td>claim mistake “carefully considered” but…why</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  \\\n",
       "0    If you’ve been off of any GLP-1 type peptide f...   \n",
       "1    Is he the jerk it sounds like he is?  He must ...   \n",
       "2    Honestly that’s heartbreaking her mom does tha...   \n",
       "3    No. As dogs do not prepare their own food, it'...   \n",
       "4    No.\\n\\nDo you need help building a diet plan f...   \n",
       "..                                                 ...   \n",
       "668    I need this shirt I hope they release it again!   \n",
       "669  Any notable departures in their patent departm...   \n",
       "671  Fortune falsely cites \"a recent report in *Sci...   \n",
       "672                        ![gif](giphy|GDnomdqpSHlIs)   \n",
       "673  They claim there was no mistake and this was “...   \n",
       "\n",
       "                                          cleaned_post  cluster  sentiment  \\\n",
       "0    you’ve glp1 type peptide 3 months act like you...        1          1   \n",
       "1    jerk sounds like must feel like loser failure ...        0          0   \n",
       "2                    honestly that’s heartbreaking mom        0          0   \n",
       "3    dogs prepare food easy put weight loss diet se...        3          1   \n",
       "4        need help building diet plan dog hypothetical        1          1   \n",
       "..                                                 ...      ...        ...   \n",
       "668                            need shirt hope release        1          0   \n",
       "669  notable departures patent department last year...        1          1   \n",
       "671  fortune falsely cites recent report science ac...        0          0   \n",
       "672                              gifgiphygdnomdqpshlis        0          0   \n",
       "673       claim mistake “carefully considered” but…why        1          0   \n",
       "\n",
       "     predicted_sentiment  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                      0  \n",
       "3                      1  \n",
       "4                      1  \n",
       "..                   ...  \n",
       "668                    1  \n",
       "669                    1  \n",
       "671                    0  \n",
       "672                    0  \n",
       "673                    0  \n",
       "\n",
       "[668 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: KMeans Clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb71163",
   "metadata": {},
   "source": [
    "<h2>hello<h2/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1b1e809f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 5, does not match size of target_names, 2. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mpredicted_sentiment\u001b[39m\u001b[33m'\u001b[39m] = clf.predict(X)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Classification report\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m report = \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentiment\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredicted_sentiment\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNegative\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPositive\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(report)\n\u001b[32m     15\u001b[39m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mab23\\OneDrive\\Documents\\notebooks\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mab23\\OneDrive\\Documents\\notebooks\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2945\u001b[39m, in \u001b[36mclassification_report\u001b[39m\u001b[34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[39m\n\u001b[32m   2939\u001b[39m         warnings.warn(\n\u001b[32m   2940\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2941\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[32m   2942\u001b[39m             )\n\u001b[32m   2943\u001b[39m         )\n\u001b[32m   2944\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2945\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2946\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m, does not match size of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2947\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m. Try specifying the labels \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2948\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparameter\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[32m   2949\u001b[39m         )\n\u001b[32m   2950\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2951\u001b[39m     target_names = [\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[31mValueError\u001b[39m: Number of classes, 5, does not match size of target_names, 2. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "# Step 4: Sentiment Classification (Optional)\n",
    "# Dummy sentiment labels (replace with actual labels if available)\n",
    "df['sentiment'] = df['cluster']  # 1: Positive, 0: Negative\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, df['sentiment'])\n",
    "\n",
    "# Predict sentiment\n",
    "df['predicted_sentiment'] = clf.predict(X)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(df['sentiment'], df['predicted_sentiment'], target_names=['Negative', 'Positive'])\n",
    "print(report)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a1de380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.99      0.79      0.88       171\n",
      "    Positive       0.52      1.00      0.69       268\n",
      "     Neutral       1.00      0.11      0.20        81\n",
      "       Mixed       1.00      0.03      0.06        60\n",
      "       Other       1.00      0.10      0.19        88\n",
      "\n",
      "    accuracy                           0.63       668\n",
      "   macro avg       0.90      0.41      0.40       668\n",
      "weighted avg       0.81      0.63      0.56       668\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_post</th>\n",
       "      <th>cluster</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If you’ve been off of any GLP-1 type peptide f...</td>\n",
       "      <td>you’ve glp1 type peptide 3 months act like you...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is he the jerk it sounds like he is?  He must ...</td>\n",
       "      <td>jerk sounds like must feel like loser failure ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honestly that’s heartbreaking her mom does tha...</td>\n",
       "      <td>honestly that’s heartbreaking mom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No. As dogs do not prepare their own food, it'...</td>\n",
       "      <td>dogs prepare food easy put weight loss diet se...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No.\\n\\nDo you need help building a diet plan f...</td>\n",
       "      <td>need help building diet plan dog hypothetical</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>I need this shirt I hope they release it again!</td>\n",
       "      <td>need shirt hope release</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Any notable departures in their patent departm...</td>\n",
       "      <td>notable departures patent department last year...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Fortune falsely cites \"a recent report in *Sci...</td>\n",
       "      <td>fortune falsely cites recent report science ac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>![gif](giphy|GDnomdqpSHlIs)</td>\n",
       "      <td>gifgiphygdnomdqpshlis</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>They claim there was no mistake and this was “...</td>\n",
       "      <td>claim mistake “carefully considered” but…why</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  \\\n",
       "0    If you’ve been off of any GLP-1 type peptide f...   \n",
       "1    Is he the jerk it sounds like he is?  He must ...   \n",
       "2    Honestly that’s heartbreaking her mom does tha...   \n",
       "3    No. As dogs do not prepare their own food, it'...   \n",
       "4    No.\\n\\nDo you need help building a diet plan f...   \n",
       "..                                                 ...   \n",
       "668    I need this shirt I hope they release it again!   \n",
       "669  Any notable departures in their patent departm...   \n",
       "671  Fortune falsely cites \"a recent report in *Sci...   \n",
       "672                        ![gif](giphy|GDnomdqpSHlIs)   \n",
       "673  They claim there was no mistake and this was “...   \n",
       "\n",
       "                                          cleaned_post  cluster  sentiment  \\\n",
       "0    you’ve glp1 type peptide 3 months act like you...        1          1   \n",
       "1    jerk sounds like must feel like loser failure ...        0          0   \n",
       "2                    honestly that’s heartbreaking mom        0          0   \n",
       "3    dogs prepare food easy put weight loss diet se...        3          3   \n",
       "4        need help building diet plan dog hypothetical        1          1   \n",
       "..                                                 ...      ...        ...   \n",
       "668                            need shirt hope release        1          1   \n",
       "669  notable departures patent department last year...        1          1   \n",
       "671  fortune falsely cites recent report science ac...        0          0   \n",
       "672                              gifgiphygdnomdqpshlis        0          0   \n",
       "673       claim mistake “carefully considered” but…why        1          1   \n",
       "\n",
       "     predicted_sentiment  \n",
       "0                      1  \n",
       "1                      1  \n",
       "2                      0  \n",
       "3                      1  \n",
       "4                      1  \n",
       "..                   ...  \n",
       "668                    1  \n",
       "669                    1  \n",
       "671                    0  \n",
       "672                    0  \n",
       "673                    1  \n",
       "\n",
       "[668 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Sentiment Classification (Optional)\n",
    "# Dummy sentiment labels (replace with actual labels if available)\n",
    "df['sentiment'] = df['cluster']  # 1: Positive, 0: Negative\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, df['sentiment'])\n",
    "\n",
    "# Predict sentiment\n",
    "df['predicted_sentiment'] = clf.predict(X)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(df['sentiment'], df['predicted_sentiment'], target_names=['Negative', 'Positive', 'Neutral', 'Mixed', 'Other'])\n",
    "print(report)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
